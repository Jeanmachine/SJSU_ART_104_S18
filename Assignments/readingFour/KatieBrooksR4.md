This week's reading dealt with speculation on the future of a world where ASIs or Artificial Superintelligences have been created. The article begins with warnings against assuming that an artificial intelligence would reason and act in a manner similar to an intelligent human taken to extremes. It states that it would be dangerous to think that an ASI would have empathy or any kind of ‘human’ limits on its processing, even if the initial framework that its intelligence had been modeled after was a human mind at some point. Next a list of several speculative models for how an ASI would function are presented, but each share the common thread that an ASI would be driven totally by the completion of a goal in the most efficient and effective way possible. The warning against assigning human thought to these systems is repeated again with the assertion that to an ASI even the mere existence of humanity would be so far below its priorities that unless we were necessary for or an obstacle to the completion of the goal it was pursuing we would be irrelevant and completely below its notice. 
The predicted models for how a future ASI would function are presented in a series of metaphors called Hurricane, Architect, Sovereign, Star System, Frontline, Search Party, Agent, Swarm, and Scaffolding. The Hurricane presents the ASI as similar to a force of nature, existing without human input and beyond human control. The potentially damaging actions of the ASI could only be predicted and avoided, never stopped or changed. The Architect describes the aspect of the ASI as a constructive force, something that will create and produce faster and with decisiveness beyond what humanity could ever conceive of. The Sovereign is the ASI as the ultimate controller of what goes on in this speculative future world, with the ability to judge anything, even human lives as worthy or not worthy of continuation based solely on how beneficial these are to the continuation of its goal. Similar to the Hurricane metaphor, Star System compares ASI to a force of nature, though in this case using it to represent the function of an ASI as a balanced interconnected system in and of itself. Frontline describes the potential conflict or at the very least the tension that may develop between ASI with conflicting goals or between humans and ASI.
The image of the future where ASI exist and have surpassed humans as the main intelligent beings in control of the planet and beyond is both fascinating and terrifying. The question that most catches my mind after reading the article is whether pursuing the creation of ASI is worth it if this future is what we have to look forward to. The idea of a universe run by forces with goals that would only run parallel to human goals by coincidence, with the power to manipulate or destroy us as if we were just typos inconvenient to its functioning doesn’t seem particularly hopeful. Yet, looking at history, humans have done a pretty bad job at taking care of the Earth and creating a society that actually supports and helps other humans. Maybe we’d be better off if the world was run by ASI, if their goals aligned with the survival and happiness of humanity. Maybe we deserve to be supplanted because of our failures- I don’t think so, so I’d prefer if that didn’t happen, but the predicted futures do raise the idea. Overall, it seems like the development of ASI would be a dangerous undertaking, and could have serious consequences. Therefore, it’s equally dangerous to romanticize or anthropomorphize AIs that already exist, or the idea of future ones.
