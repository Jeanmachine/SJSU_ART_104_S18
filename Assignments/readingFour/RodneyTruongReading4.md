Rodney Truong

Reading 4

The emergence of artificial superintelligence is something we, as humans, have always wondered. What would beings who hold unlimited undying knowledge do for us or for themselves? Khan’s article starts off by addressing this question, evaluating the endless possibilities of the near future. Artificial superintelligence is defined by the author as a being that exceeds all human beings in every cognitive field. One step below it is, AGI, or artificial general intelligence. AGI is essentially a replica of a human brain, human qualities involving morals, the ability to reason learn and improve. We haven’t yet achieved this level in AI, but there are many who suggest it will happen soon. If such machines exist then what does this mean for humanity? These beings which are beyond human understanding, can we really coexist with them? AI is immortal, and will “live” through generations of humanity. How will it evolve?

Reading through this article, I couldn’t help but think of a game I’ve recently played, Nier:Automata. The game follows humanity as they are pushed off earth by invading aliens. The aliens used machines / robots they built to combat the humans who are eventually pushed to living on the moon. Centuries pass and in order to combat the alien machines, humanity built androids, or machines with human appearance. Back on earth however, it’s revealed that the aliens have already been killed off by their own machines who have taken human form. After playing that game, I can only wonder if AI could lead to the end of humanity. If we do get to the point of ASI, will we still be able to control it? Or will it control us? This being that could live on the internet, will have the power to manipulate anything it wishes. It’s reasoning will be beyond our comprehension.While the goal of artificial superintelligence is steadily being worked on, I don’t think we should welcome it with open arms, rather, cautious ones. 
