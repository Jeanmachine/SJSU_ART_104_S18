Faustino Ortiz
Art 104 Section 1
2/20/18

                                                          Reading 4 Response
                                                         
In Khan's article "Towards a Poetics of Artificial Superintelligence" she talks about artificial intelligence and how the world will
eventually have these AI's that help run the world. She realizes that there could be dangers of having these AI's because they could 
evolve to the point where they would want to wipe out the human race and let the robots gain control as shown many different films.
However she talks about possible ways that AI's could be programmed to help ensure that they will not turn on us.By assigning them specific 
roles that will help them become benefcial to human life and so that we coincide with them with no problems.

Kahn mentions that by programming the AI to a specific role, it reduces the chance of them being to adapt and evolve fast enough for them
to want to rebel against us. If programmers were more broad in the process, it would be hard to code in the many factors of the outside 
world for a robot that it could not keep up with a human mind. Some of the roles she talked about included Agent, Architect, and Soverign.
They will address specific topics that fit their given roles whether it be on how to construct certain buildings to deciding on how to handle 
a crisis that could affect both human and animals. By having them focus on this specific issue it decreases the chance of the AI being 
overwhelmed with all these issues and make it go out of control.

Now with her suggestions on how to program AI makes sense but I don't think it'll be enough. In Marvel comics as an example a robot named 
Ultron was created with one goal to maintain peace in the world. It was a broad goal but again it was one simple task that it was given. 
It ended up turning against humanity seeing as the only way to maintain peace is to eraticate the human race completely. What's to say that 
can't be done also with the AI tasked to handle Soveringty issues decided to humans are to much of a burden and decides that they should be
the ones to perish and priority be given to nature. Humans overall are very troublesome and have cause some damage to the enviornment in order
to survive. So seeing this as a possibility makes me question if AI can truly be programmed to truly balance between human life and the plant 
life. Could it be done? I'm sure it can be but will technology be advanced enough for us to code this in as a a factor to consider? 
